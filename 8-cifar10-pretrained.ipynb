{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-04T07:46:32.235372Z","iopub.execute_input":"2023-08-04T07:46:32.235773Z","iopub.status.idle":"2023-08-04T07:46:32.249165Z","shell.execute_reply.started":"2023-08-04T07:46:32.235739Z","shell.execute_reply":"2023-08-04T07:46:32.248072Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Keras의 Pretrained 모델 로딩 및 모델 구조 확인. ","metadata":{}},{"cell_type":"code","source":"#from tensorflow.keras.applications.vgg16 import VGG16\n#from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:46:34.435744Z","iopub.execute_input":"2023-08-04T07:46:34.436100Z","iopub.status.idle":"2023-08-04T07:46:42.255790Z","shell.execute_reply.started":"2023-08-04T07:46:34.436071Z","shell.execute_reply":"2023-08-04T07:46:42.254776Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model = VGG16() # 16은 layer가 16개인것을 의미\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:46:42.257568Z","iopub.execute_input":"2023-08-04T07:46:42.258328Z","iopub.status.idle":"2023-08-04T07:47:04.853230Z","shell.execute_reply.started":"2023-08-04T07:46:42.258290Z","shell.execute_reply":"2023-08-04T07:47:04.852528Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 17s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n predictions (Dense)         (None, 1000)              4097000   \n                                                                 \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet') # include_top=False (마지막 classifier 레이어를 사용하지 않는다는 의미), weights는 이전의 가중치 그대로 이용\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:48:26.643554Z","iopub.execute_input":"2023-08-04T07:48:26.644238Z","iopub.status.idle":"2023-08-04T07:48:29.605839Z","shell.execute_reply.started":"2023-08-04T07:48:26.644206Z","shell.execute_reply":"2023-08-04T07:48:29.605072Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 2s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n                                                                 \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Keras의 Model 역시 Functional임. ","metadata":{}},{"cell_type":"code","source":"print('model:', model)\nprint('model output:', model.output) # 맨마지막의 layer를 의미","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:50:16.784986Z","iopub.execute_input":"2023-08-04T07:50:16.785349Z","iopub.status.idle":"2023-08-04T07:50:16.791079Z","shell.execute_reply.started":"2023-08-04T07:50:16.785321Z","shell.execute_reply":"2023-08-04T07:50:16.790144Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"model: <keras.engine.functional.Functional object at 0x7997c80fa6b0>\nmodel output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. ","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:05:36.583978Z","iopub.execute_input":"2023-08-04T08:05:36.584337Z","iopub.status.idle":"2023-08-04T08:05:36.589305Z","shell.execute_reply.started":"2023-08-04T08:05:36.584308Z","shell.execute_reply":"2023-08-04T08:05:36.588070Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\n# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n\nbase_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\nbm_output = base_model.output\n'''\n아래도 가능하다.\ninput_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\nbase_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\nVGG16()\n'''\n\n# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \nx = GlobalAveragePooling2D()(bm_output)\n# x = Dropout(rate=0.5)(x)\nx = Dense(50, activation='relu', name='fc1')(x)\n# x = Dropout(rate=0.2)(x)\noutput = Dense(10, activation='softmax', name='output')(x)\n\n#model = Model(inputs=input_tensor, outputs=output)\nmodel = Model(inputs=base_model.input, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:05:38.899692Z","iopub.execute_input":"2023-08-04T08:05:38.900055Z","iopub.status.idle":"2023-08-04T08:05:39.299108Z","shell.execute_reply.started":"2023-08-04T08:05:38.900027Z","shell.execute_reply":"2023-08-04T08:05:39.298379Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n                                                                 \n global_average_pooling2d (G  (None, 512)              0         \n lobalAveragePooling2D)                                          \n                                                                 \n fc1 (Dense)                 (None, 50)                25650     \n                                                                 \n output (Dense)              (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 14,740,848\nTrainable params: 14,740,848\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels, scaling=True):\n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# random seed는 2021로 고정.\nset_random_seed(2021)\n# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:12:55.359486Z","iopub.execute_input":"2023-08-04T08:12:55.359858Z","iopub.status.idle":"2023-08-04T08:13:04.977544Z","shell.execute_reply.started":"2023-08-04T08:12:55.359829Z","shell.execute_reply":"2023-08-04T08:13:04.976519Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 6s 0us/step\n(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    # rotation_range=20,\n    #zoom_range=(0.7, 0.9),\n    horizontal_flip=True,\n    #vertical_flip=True,\n    rescale=1/255.0\n)\nvalid_generator = ImageDataGenerator(rescale=1/255.0)\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:19:21.173466Z","iopub.execute_input":"2023-08-04T08:19:21.174347Z","iopub.status.idle":"2023-08-04T08:19:21.180971Z","shell.execute_reply.started":"2023-08-04T08:19:21.174313Z","shell.execute_reply":"2023-08-04T08:19:21.179866Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Keras CNN 모델 생성 함수. ","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:19:25.507638Z","iopub.execute_input":"2023-08-04T08:19:25.508001Z","iopub.status.idle":"2023-08-04T08:19:25.512576Z","shell.execute_reply.started":"2023-08-04T08:19:25.507973Z","shell.execute_reply":"2023-08-04T08:19:25.511662Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ndef create_model(verbose=False):\n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    bm_output = base_model.output\n\n    x = GlobalAveragePooling2D()(bm_output)\n    #x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    #x = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n\n    model = Model(inputs=input_tensor, outputs=output)\n    if verbose:\n        model.summary()\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:19:37.463619Z","iopub.execute_input":"2023-08-04T08:19:37.464008Z","iopub.status.idle":"2023-08-04T08:19:37.474039Z","shell.execute_reply.started":"2023-08-04T08:19:37.463980Z","shell.execute_reply":"2023-08-04T08:19:37.472903Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# model.summary()보면 마지막 레이어의 x, y크기가 1 바이 1이라서 추상적인 데이터를 많이 담지 못함 => 모델 성능이 그렇게 좋지못함 (왜냐하면 VGG16은 224 바이 224를 입력으로 받게 되어있기 때문이다.)\nvgg_model = create_model(verbose=True)\nvgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:19:47.484185Z","iopub.execute_input":"2023-08-04T08:19:47.484665Z","iopub.status.idle":"2023-08-04T08:19:48.020544Z","shell.execute_reply.started":"2023-08-04T08:19:47.484624Z","shell.execute_reply":"2023-08-04T08:19:48.019628Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n                                                                 \n global_average_pooling2d_1   (None, 512)              0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n fc1 (Dense)                 (None, 50)                25650     \n                                                                 \n output (Dense)              (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 14,740,848\nTrainable params: 14,740,848\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\ntr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\nhistory = vgg_model.fit(flow_tr_gen, epochs=40, \n                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n                    validation_data=flow_val_gen, \n                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                    callbacks=[rlr_cb, ely_cb])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:20:13.445736Z","iopub.execute_input":"2023-08-04T08:20:13.446212Z","iopub.status.idle":"2023-08-04T08:23:54.611310Z","shell.execute_reply.started":"2023-08-04T08:20:13.446168Z","shell.execute_reply":"2023-08-04T08:23:54.610366Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/40\n665/665 [==============================] - 30s 25ms/step - loss: 2.4359 - accuracy: 0.2563 - val_loss: 1.6457 - val_accuracy: 0.3912 - lr: 0.0010\nEpoch 2/40\n665/665 [==============================] - 16s 24ms/step - loss: 5.3218 - accuracy: 0.1452 - val_loss: 2.3035 - val_accuracy: 0.0960 - lr: 0.0010\nEpoch 3/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3036 - val_accuracy: 0.0928 - lr: 0.0010\nEpoch 4/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3038 - val_accuracy: 0.0928 - lr: 0.0010\nEpoch 5/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3038 - val_accuracy: 0.0928 - lr: 0.0010\nEpoch 6/40\n664/665 [============================>.] - ETA: 0s - loss: 2.3027 - accuracy: 0.0992\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n665/665 [==============================] - 16s 24ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3038 - val_accuracy: 0.0928 - lr: 0.0010\nEpoch 7/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3037 - val_accuracy: 0.0928 - lr: 2.0000e-04\nEpoch 8/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3037 - val_accuracy: 0.0928 - lr: 2.0000e-04\nEpoch 9/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3037 - val_accuracy: 0.0928 - lr: 2.0000e-04\nEpoch 10/40\n665/665 [==============================] - 16s 24ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3036 - val_accuracy: 0.0928 - lr: 2.0000e-04\nEpoch 11/40\n663/665 [============================>.] - ETA: 0s - loss: 2.3026 - accuracy: 0.1012\nEpoch 11: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n665/665 [==============================] - 16s 24ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3036 - val_accuracy: 0.0928 - lr: 2.0000e-04\nEpoch 11: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.0)\nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nvgg_model.evaluate(flow_test_gen)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:25:43.623091Z","iopub.execute_input":"2023-08-04T08:25:43.623457Z","iopub.status.idle":"2023-08-04T08:25:46.232717Z","shell.execute_reply.started":"2023-08-04T08:25:43.623426Z","shell.execute_reply":"2023-08-04T08:25:46.231659Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 2s 10ms/step - loss: 2.3033 - accuracy: 0.1001\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[2.3032591342926025, 0.10010000318288803]"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:25:49.416885Z","iopub.execute_input":"2023-08-04T08:25:49.417244Z","iopub.status.idle":"2023-08-04T08:25:49.731520Z","shell.execute_reply.started":"2023-08-04T08:25:49.417217Z","shell.execute_reply":"2023-08-04T08:25:49.730540Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x400 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"### 지금까지의 로직들을 함수화 ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import Xception\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels, scaling=True):\n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \ndef get_resized_images(images, resize=64):\n    image_cnt = images.shape[0]\n    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n    for i in range(image_cnt):\n        resized_image = cv2.resize(images[i], (resize, resize))\n        resized_images[i] = resized_image\n    \n    return resized_images\n\ndef create_model(model_name='vgg16', verbose=False):\n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    if model_name == 'vgg16':\n        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'resnet50':\n        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    elif model_name == 'xception':\n        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n    \n    bm_output = base_model.output\n\n    x = GlobalAveragePooling2D()(bm_output)\n    if model_name != 'vgg16': # vgg16일 경우 마지막까지 거칠경우 feature map이 너무 작아지므로 Dropout은 수행하지 않을 것이다.\n        x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n\n    model = Model(inputs=input_tensor, outputs=output)\n    model.summary()\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:26:24.349625Z","iopub.execute_input":"2023-08-04T08:26:24.349982Z","iopub.status.idle":"2023-08-04T08:26:24.552072Z","shell.execute_reply.started":"2023-08-04T08:26:24.349953Z","shell.execute_reply":"2023-08-04T08:26:24.551105Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64\n\ndef do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n    set_random_seed(2021)\n    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n    \n    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n    if image_size > 32:\n        tr_images = get_resized_images(tr_images)\n        val_images = get_resized_images(val_images)\n        test_images = get_resized_images(test_images)\n    \n    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n    train_generator = ImageDataGenerator(\n        horizontal_flip=True,\n        rescale=1/255.0\n    )\n    valid_generator = ImageDataGenerator(rescale=1/255.0)\n    test_generator = ImageDataGenerator(rescale=1/255.0)\n\n    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n    \n    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n    model = create_model(model_name=model_name, verbose=True)\n    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n    \n    tr_data_len = tr_images.shape[0]\n    val_data_len = val_images.shape[0]\n    history = model.fit(flow_tr_gen, epochs=40, \n                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                        callbacks=[rlr_cb, ely_cb])\n    # 테스트 데이터 세트로 모델 성능 검증 \n    evaluation_result = model.evaluate(flow_test_gen)\n    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n    \n    return history, evaluation_result","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:41:34.666902Z","iopub.execute_input":"2023-08-04T08:41:34.667265Z","iopub.status.idle":"2023-08-04T08:41:34.680124Z","shell.execute_reply.started":"2023-08-04T08:41:34.667237Z","shell.execute_reply":"2023-08-04T08:41:34.678947Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect() # 메모리를 비워놓기 위해 실행","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:48:12.317330Z","iopub.execute_input":"2023-08-04T08:48:12.317728Z","iopub.status.idle":"2023-08-04T08:48:12.571621Z","shell.execute_reply.started":"2023-08-04T08:48:12.317697Z","shell.execute_reply":"2023-08-04T08:48:12.570445Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"5491"},"metadata":{}}]},{"cell_type":"code","source":"# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\nhistory, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T08:48:23.570220Z","iopub.execute_input":"2023-08-04T08:48:23.570579Z","iopub.status.idle":"2023-08-04T09:14:28.524641Z","shell.execute_reply.started":"2023-08-04T08:48:23.570549Z","shell.execute_reply":"2023-08-04T09:14:28.523421Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 3s 0us/step\nModel: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_5 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n                                                                                                  \n block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_5[0][0]']                \n                                                                                                  \n block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n ation)                                                                                           \n                                                                                                  \n block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n                                                                                                  \n block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n                                                                                                  \n block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n ation)                                                                                           \n                                                                                                  \n block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n                                                                                                  \n block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n 2D)                                                                                              \n                                                                                                  \n block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n                                                                                                  \n block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n                                                                                                  \n batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n                                                                  'batch_normalization[0][0]']    \n                                                                                                  \n block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n n)                                                                                               \n                                                                                                  \n block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n                                                                                                  \n block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n                                                                  'batch_normalization_1[0][0]']  \n                                                                                                  \n block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n                                                                                                  \n block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n                                                                  'batch_normalization_2[0][0]']  \n                                                                                                  \n block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n lization)                                                                                        \n                                                                                                  \n add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n                                                                  'add_2[0][0]']                  \n                                                                                                  \n block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n lization)                                                                                        \n                                                                                                  \n add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n                                                                  'add_3[0][0]']                  \n                                                                                                  \n block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n lization)                                                                                        \n                                                                                                  \n add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n                                                                  'add_4[0][0]']                  \n                                                                                                  \n block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n lization)                                                                                        \n                                                                                                  \n add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n                                                                  'add_5[0][0]']                  \n                                                                                                  \n block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n n)                                                                                               \n                                                                                                  \n block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n n)                                                                                               \n                                                                                                  \n block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n 2D)                                                                                              \n                                                                                                  \n block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n lization)                                                                                        \n                                                                                                  \n add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n                                                                  'add_6[0][0]']                  \n                                                                                                  \n block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n on)                                                                                              \n                                                                                                  \n block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n alization)                                                                                       \n                                                                                                  \n add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n                                                                  'add_7[0][0]']                  \n                                                                                                  \n block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n on)                                                                                              \n                                                                                                  \n block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n alization)                                                                                       \n                                                                                                  \n add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n                                                                  'add_8[0][0]']                  \n                                                                                                  \n block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n on)                                                                                              \n                                                                                                  \n block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n alization)                                                                                       \n                                                                                                  \n add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n                                                                  'add_9[0][0]']                  \n                                                                                                  \n block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n on)                                                                                              \n                                                                                                  \n block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n alization)                                                                                       \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n                                                                                                  \n block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n                                                                  'batch_normalization_3[0][0]']  \n                                                                                                  \n block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n v2D)                                                                                             \n                                                                                                  \n block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n v2D)                                                                                             \n                                                                                                  \n block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n on)                                                                                              \n                                                                                                  \n global_average_pooling2d_2 (Gl  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n obalAveragePooling2D)                                                                            \n                                                                                                  \n dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d_2[0][0\n                                                                 ]']                              \n                                                                                                  \n fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n                                                                                                  \n output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n                                                                                                  \n==================================================================================================\nTotal params: 20,964,440\nTrainable params: 20,909,912\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\nEpoch 1/40\n665/665 [==============================] - 100s 102ms/step - loss: 0.7382 - accuracy: 0.7582 - val_loss: 0.5913 - val_accuracy: 0.8113 - lr: 0.0010\nEpoch 2/40\n665/665 [==============================] - 66s 99ms/step - loss: 0.3982 - accuracy: 0.8720 - val_loss: 0.4817 - val_accuracy: 0.8441 - lr: 0.0010\nEpoch 3/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.3064 - accuracy: 0.9004 - val_loss: 0.4172 - val_accuracy: 0.8643 - lr: 0.0010\nEpoch 4/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.2537 - accuracy: 0.9172 - val_loss: 0.3206 - val_accuracy: 0.8969 - lr: 0.0010\nEpoch 5/40\n665/665 [==============================] - 66s 99ms/step - loss: 0.2169 - accuracy: 0.9285 - val_loss: 0.4378 - val_accuracy: 0.8691 - lr: 0.0010\nEpoch 6/40\n665/665 [==============================] - 66s 99ms/step - loss: 0.1730 - accuracy: 0.9425 - val_loss: 0.4386 - val_accuracy: 0.8741 - lr: 0.0010\nEpoch 7/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.1531 - accuracy: 0.9500 - val_loss: 0.3922 - val_accuracy: 0.8823 - lr: 0.0010\nEpoch 8/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.1397 - accuracy: 0.9548 - val_loss: 0.3682 - val_accuracy: 0.8931 - lr: 0.0010\nEpoch 9/40\n665/665 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9526\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n665/665 [==============================] - 65s 98ms/step - loss: 0.1474 - accuracy: 0.9526 - val_loss: 0.4600 - val_accuracy: 0.8733 - lr: 0.0010\nEpoch 10/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.2307 - val_accuracy: 0.9391 - lr: 2.0000e-04\nEpoch 11/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.2548 - val_accuracy: 0.9368 - lr: 2.0000e-04\nEpoch 12/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.2668 - val_accuracy: 0.9340 - lr: 2.0000e-04\nEpoch 13/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.2936 - val_accuracy: 0.9344 - lr: 2.0000e-04\nEpoch 14/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.2961 - val_accuracy: 0.9363 - lr: 2.0000e-04\nEpoch 15/40\n665/665 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9957\nEpoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n665/665 [==============================] - 65s 98ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.2994 - val_accuracy: 0.9373 - lr: 2.0000e-04\nEpoch 16/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.2891 - val_accuracy: 0.9405 - lr: 4.0000e-05\nEpoch 17/40\n665/665 [==============================] - 65s 98ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.2898 - val_accuracy: 0.9397 - lr: 4.0000e-05\nEpoch 18/40\n665/665 [==============================] - 66s 99ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3026 - val_accuracy: 0.9408 - lr: 4.0000e-05\nEpoch 19/40\n665/665 [==============================] - 66s 99ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.3005 - val_accuracy: 0.9415 - lr: 4.0000e-05\nEpoch 20/40\n665/665 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\nEpoch 20: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n665/665 [==============================] - 65s 98ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.3054 - val_accuracy: 0.9412 - lr: 4.0000e-05\nEpoch 20: early stopping\n157/157 [==============================] - 4s 23ms/step - loss: 0.3452 - accuracy: 0.9332\n테스트 데이터 세트 evaluation 결과: [0.34521031379699707, 0.9332000017166138]\n","output_type":"stream"}]},{"cell_type":"code","source":"print('테스트 데이터세트 검증 결과:', evaluation_result)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T09:14:38.615543Z","iopub.execute_input":"2023-08-04T09:14:38.615928Z","iopub.status.idle":"2023-08-04T09:14:38.621283Z","shell.execute_reply.started":"2023-08-04T09:14:38.615896Z","shell.execute_reply":"2023-08-04T09:14:38.620129Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"테스트 데이터세트 검증 결과: [0.34521031379699707, 0.9332000017166138]\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T09:14:41.346392Z","iopub.execute_input":"2023-08-04T09:14:41.346777Z","iopub.status.idle":"2023-08-04T09:14:41.662835Z","shell.execute_reply.started":"2023-08-04T09:14:41.346747Z","shell.execute_reply":"2023-08-04T09:14:41.661877Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x400 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAqgAAAFfCAYAAACCxz5gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABXfElEQVR4nO3dd3wUdf7H8dfupndCIAVI6L33apeiIugpqBRRbHd6GrlD5dQ75efJ2TsonopYsYuKIDbKIaKQgPQikAAJIUgS0pPd+f0xSSAhQPpskvfz8ZjHzs7Ozn4mwc3b78z3+7UZhmEgIiIiIuIm7FYXICIiIiJyMgVUEREREXErCqgiIiIi4lYUUEVERETErSigioiIiIhbUUAVEREREbeigCoiIiIibsXD6gJqisvl4tChQwQGBmKz2awuR0RERETKMAyD48ePExUVhd1++nbSBhNQDx06RKtWrawuQ0RERETOIjExkZYtW5729QYTUAMDAwHzhIOCgiyuRkRERETKysjIoFWrViW57XQaTEAtvqwfFBSkgCoiIiLixs52O6Y6SYmIiIiIW1FAFRERERG3ooAqIiIiIm6lwdyDWhEul4v8/Hyry6i3PD09cTgcVpchIiIiDVyjCaj5+fns3bsXl8tldSn1WkhICBERERprVkRERGpNowiohmGQlJSEw+GgVatWZxwYVspnGAbZ2dmkpKQAEBkZaXFFIiIi0lA1ioBaWFhIdnY2UVFR+Pn5WV1OveXr6wtASkoKzZs31+V+ERERqRWNoinR6XQC4OXlZXEl9V9xwC8oKLC4EhEREWmoGkVALab7JqtPP0MRERGpbY0qoIqIiIiI+2sU96CKiIhIw2cYBnmFLvKdLvIKih+dJc/zCl3kF7rIK3QWPZ54nnfS88JyRvyxUfoKYtkLiuVeXyyzU9l9yh7DMMxzcBoGLgNcLgNX0brTZWAUrxtF6y6K9jUwivYpu+4yKHose0zz/S7DYHT3CG4a0bZiP+Q6ooDaSLRu3ZrY2FhiY2OtLkVERNxcgdPF0cx8UjPzOJKZx9HMfHILnCUB6dSwQ1EwOv3rhlF239Ih6nSvlwTKUqHzNOHTqaEkq6JLZJDVJZxCAdWNnXfeefTu3Ztnn3222sf65Zdf8Pf3r35RIiJSL+UWOEnNzCM1M5/U43kczTLXjxzPK9pe9FpmHmnZDaMjrJeHHW+HHW9PO14OO96ejqJHe8mjt8ep2zzOMhylYRiln5e7T5nnZfY69XWw28Bus520gMNuw1Zm3VH03G4/sZ/dZit6XuY9RceyFW0/eb/iz4kOdb8RjhRQ6zHDMHA6nXh4nP3X2KxZszqoSESkbuUWOElKz8UwDIJ8PQny8cTLo/F0r8jKKywJl0eO55uh83j+SYHzRCA9nldYqWPbbdA0wJum/l40C/TGz8tREmhsJeGGUwKP7eTtNrNzraOCr9tspQOXzQbeHkUh0sNurnva8XI4SgXKsuHT28Pcpo699VejDKiGYZBT4LTks309HRX6D2batGmsWLGCFStW8NxzzwHwxhtvcMMNN7B06VLuv/9+Nm3axLJly4iOjmbGjBmsXbuWrKwsunTpwpw5c7joootKjlf2Er/NZuPVV1/lq6++YtmyZbRo0YKnnnqKyy+/vFbOW0Skslwug9SsPA6l5XIoLYdDaTkcLHos3nY069Tpq3087QT5eBLs61kUWj1KwmuQr0fRY3nPPQisg4Bb/DcoK89JVl4hWfmFZOcXrec5zed5hWQVbcs+6TEzr5CM3AIzeB7Pr/TfMk+HjbAA76LFi7AAb5oWrTcL9C71WhM/L+x2BTyxRqMMqDkFTrr+c5kln7119ij8vM7+Y3/uuefYuXMn3bt3Z/bs2QBs2bIFgHvuuYcnn3yStm3bEhISwoEDB7jkkkt45JFH8PHx4c0332Ts2LHs2LGD6Ojo037Gww8/zOOPP84TTzzBCy+8wKRJk9i/fz+hoaE1c7IiImeQnV9YKnyaAbToeXoOSWm5Fbqn0NfTgYfdVtJCmFvgIrcgj5TjeVWqy9fTcUpwLS/QBnh7kFfoIju/kMy8QrKLwmVWUbg8XcjMyi885fJudfh42k8Klt40C/Qq9bxpURBtFuBNkK+HWhWlXmiUAbU+CA4OxsvLCz8/PyIiIgDYvn07ALNnz+biiy8u2bdp06b06tWr5PkjjzzCp59+yuLFi7njjjtO+xnTpk3j2muvBeDRRx/lhRdeYN26dYwePbo2TklEGhGXy+BIZt5JLZ5mq+fJz49V4D5Huw3Cg3yICvElMtiHFiG+RJUs5vNgX09sNhtOl0FmrtnCmJ5TQEZuARk5hUWPBWTkFhY9lt5+vGh7ccDNKXCSU+DkcEbVAm5F2Wzg7+WBn5cDf+8Tj/5eDvyKHs3nHvh5O/D38sDf24MAb49SIdTfW3/KpeFplP+qfT0dbJ09yrLPrq7+/fuXep6VlcXDDz/Ml19+yaFDhygsLCQnJ4eEhIQzHqdnz54l6/7+/gQGBpKSklLt+kTE/RmGYfZ+LnSRW+As6gXtJLfoMa/ARW7Zx4ITQ/EUr5d9TM8pICk9h+T0XAqcZ28mDPD2KAqdPiXBs8VJATQ8yAdPR8UuuTvsNoL9PAn286RVFX4mxQH3RLg9c8g9nluIj6eDAO8zhUwP/L1PvGbua27z8XDoErrIaTTKgGqz2Sp0md1dle2NP3PmTJYtW8aTTz5J+/bt8fX15aqrriI//9R7s07m6elZ6rnNZsNVzthvIlJ/JP6RzbItyfxvdyqZeYUnAmc5YbImLzOXx2G3ERHkUyp8mgH0xPMgH8+zH6iOnBxwRcRa9TelNQJeXl44nWe/AX7VqlVMmzaNK664AoDMzEz27dtXy9WJiLvYnZLJsi3JfL05ic0HMyr9/uKe0j6ejjM+ep/tdQ8HAT4etAjxITLYl+aB3nhUsPVTRORkCqhurHXr1vz888/s27ePgICA07Zutm/fnk8++YSxY8dis9l48MEH1RIq0oAZhsGWQxlFoTSZ3SmZJa/ZbTCwTSgXd40gKtgHb087Ph6OkvEefYoevT1PBEsNxyMi7kYB1Y39/e9/5/rrr6dr167k5OTwxhtvlLvfM888w4033sjQoUMJCwvj3nvvJSOj8q0oIuK+XC6DuMRjLN2czNItyST+kVPymqfDxrD2YYzuFsHFXcNpGuBtYaUiItVnM8pOh1BPZWRkEBwcTHp6OkFBpafsys3NZe/evbRp0wYfHx+LKmwY9LMUqTuFThc/7/2DpZuTWbYludSwST6eds7r2JzR3SM4v3Nzgn1136SIuL8z5bWTqQVVRMSN5BU6Wb0rlaWbk1m+7XCpKScDvT24sIsZSs/p2Kxed/YUETkTfbuJiFgsK6+QH3ccYemWZH7YnkLmSVNShvp7MbJrOKO6RzC0XVO8Pao/VJ2IiLtTQBURsUB6dgHfbjvM0i3JrNx5hLzCEx0bI4J8GN09glHdIhjQuol6wotIo6OAKiJSR44cz2P51sN8vTmJn/YcpdB1ogtATFM/RnePYHS3CHq1DNEA7iLSqCmgiojUosMZuXy1KYmlm5P5Zf8fpQbH7xQeaIbS7hF0jgjUUE8iIkUUUEVEaslvB9KZOP8nsvNPTLjRq2Uwo4paSts2C7CwOhER96WAKiJSC44cz+OWt34lO99J54hAJvRvxajuEbQI8bW6NBERt6eAKiJSw/ILXfz57fUkpefSrpk/H9w2xK3mnBcRcXfqGtrAtW7dmmeffbbkuc1m47PPPjvt/vv27cNmsxEfH1/rtYk0RIZh8K/Fm/l1/zECfTx4dWp/hVMRkUpSC2ojk5SURJMmTawuQ6TBevvnBN5bl4jNBs9f20f3mYqIVIECaiMTERFhdQkiDdba34/y8OItANw7ujPnd2pucUUiIvWTLvG7sVdeeYUWLVrgcrlKbb/88su5/vrr2bNnD+PGjSM8PJyAgAAGDBjAt99+e8Zjlr3Ev27dOvr06YOPjw/9+/cnLi6uNk5FpME7cCybv7yzgUKXweW9orj1nLZWlyQiUm81zoBqGJCfZc1y8iCIZ3H11VeTmprKDz/8ULLt2LFjLFu2jEmTJpGZmckll1zCt99+S1xcHKNGjWLs2LEkJCRU6PhZWVlcdtlldOrUifXr1/PQQw/x97//vdI/TpHGLju/kFsWruePrHy6twjisT/11JimIiLV0Dgv8Rdkw6NR1nz2Pw6Bl3+Fdg0NDWX06NG8++67XHjhhQB8+OGHhIaGcuGFF+JwOOjVq1fJ/o888giffvopixcv5o477jjr8d955x2cTievv/46fn5+dOvWjQMHDvDnP/+5aucm0ggZhsHMjzaxNSmDsAAvXpnSH18vh9VliYjUa42zBbUemTRpEh9//DF5eXmAGSqvueYaHA4HWVlZ3HPPPXTt2pWQkBACAgLYvn17hVtQt23bRq9evfDz8yvZNmTIkFo5D5GGau6Pe/hqUxKeDhvzJvfTOKciIjWgcbagevqZLZlWfXYljB07FpfLxVdffcWAAQNYtWoVTz/9NAAzZ85k2bJlPPnkk7Rv3x5fX1+uuuoq8vPzK3RsoxK3G4jIqb7bdpgnv9kBwMOXd2dA61CLKxIRaRgaZ0C12Sp8md1qvr6+XHnllbzzzjvs3r2bjh070q9fPwBWrVrFtGnTuOKKKwDIzMxk3759FT52165deeutt8jJycHX12z1Wbt2bY2fg0hDtDslk7vej8cwYPLgaK4bFG11SSIiDYYu8dcDkyZN4quvvuL1119n8uTJJdvbt2/PJ598Qnx8PBs3buS66647pcf/mVx33XXY7XamT5/O1q1bWbJkCU8++WRtnIJIg5KeU8AtC38lM6+Qga1D+edl3awuSUSkQVFArQcuuOACQkND2bFjB9ddd13J9meeeYYmTZowdOhQxo4dy6hRo+jbt2+FjxsQEMAXX3zB1q1b6dOnD/fffz+PPfZYbZyCSIPhdBnc9X4cv6dmERXsw9zJffHy0FepiEhNshkN5EbEjIwMgoODSU9PJygoqNRrubm57N27lzZt2uDj42NRhQ2DfpbS2P3n6+28vGIPPp52PrptKN1bBFtdkohIvXGmvHYy/W+/iEgFfR5/kJdX7AHg8at6KZyKiNQSBVQRkQr47UA693y0CYA/n9eOy3tZNJayiEgjoIAqInIWR47ncctbv5JX6OL8Ts34+8hOVpckItKgKaCKiJxBfqGLv7yznqT0XNo28+e5a/vgsGsaUxGR2qSAKiJyBg99sYVf9h0j0NuDV6f2J8jH0+qSREQavEYVUBvIgAWWqsw4qyL13dtr9/PuzwnYbPD8tX1o1yzA6pJERBqFRjGTlKenJzabjSNHjtCsWTNsNl2eqyzDMMjPz+fIkSPY7Xa8vLysLkmkVv38+1EeWrwFgJmjOnF+5+YWVyQi0ng0ioDqcDho2bIlBw4cqNRUoHIqPz8/oqOjsdsbVeO7NDIHjmXzl3c2UOgyuKxnJH8+t53VJYmINCqNIqCCOWtShw4dKCgosLqUesvhcODh4aEWaGnQcvKd3LJwPUez8ukWFcQTV/XSv3kRkTrWaAIqmAHL4XBYXYaIuCnDMJj50Ua2JmXQ1N+L+VP74+ul7wwRkbqm67QiIkXmrdjDl5uS8LDbmDupLy1CfK0uSUSkUVJAFREBvt9+mCeW7QDgocu7MahtU4srEhFpvBRQRaTR252SyV3vxWMYcN2gaCYPjrG6JBGRRk0BVUQatfScAm5Z+CvH8woZ0LoJD43tZnVJIiKNngKqiDRaTpdB7Ptx/J6aRWSwD3Mn9cPLQ1+LIiJW0zexiDRaT36zgx92HMHbw878Kf1pFuhtdUkiIoICqog0Up/HH2Tej3sAePyqnvRoGWxxRSIiUkwBVUQanc0H07n3400A3HpuW8b1bmFxRSIicjIFVBGpUwVOF3tTs0jJyKXA6arzz0/NzOOWhb+SW+Di3I7NuGdU5zqvQUREzqxRzSQlInUrLTufrUkZbEs6ztZDGWxLymBXynEKnEbJPsG+njQN8CLM35tQfy+aBnjRNMCbsAAv87n/ifUQPy8c9qpPO5pf6OIvb2/gUHoubcL8ef7aPtU6noiI1A4FVBGpNpfLYP8f2WxLMkNocRg9lJ5b7v4+nnbyC124DHOYp/ScAn4/knXWz7HbINT/RHBtGuBFWMBJwbZoW1N/M+QG+Xhgs50IoA9/sYV1+/4g0NuDV6f2J9jXs8Z+BiIiUnMUUEWkUrLzC9mefLxUEN2efJzsfGe5+7cK9aVLRBBdo4LoEhlE18ggWjbxxWWYLax/ZOWTmpnP0ay8E+uZ5vrRzHxSi7anZRfgMiA109wHMs9aq6fDVhJm/b0d/LLvGDYbPHtNb9o3D6jhn4yIiNSUKgXUuXPn8sQTT5CUlES3bt149tlnGTFixGn3f+mll3jxxRfZt28f0dHR3H///UydOrXk9QULFnDDDTec8r6cnBx8fHyqUqKIVJNhGBzOyGNrUnqpS/R7j2ZhGKfu7+1hp1NEYKkw2jkykCCf8lspHTZoGuBN0wBvOoSfvZ4Cp4tjWfkcLQquR7Pyyjyawbb49cy8Qgqc5jkczsgrOc7fR3biwi4V+EAREbFMpQPqokWLiI2NZe7cuQwbNoxXXnmFMWPGsHXrVqKjo0/Zf968ecyaNYtXX32VAQMGsG7dOm6++WaaNGnC2LFjS/YLCgpix44dpd6rcCpSN/ILXexOyTxxib7o8Vh2Qbn7Nwv0pktkEF0iA+la1CraJswfD0ft9bv0dNhpHuRD86CKfS/kFjhLWmGLQ6yfl4PR3SNqrUYREakZNsMory3k9AYNGkTfvn2ZN29eybYuXbowfvx45syZc8r+Q4cOZdiwYTzxxBMl22JjY/n1119ZvXo1YLagxsbGkpaWVuE68vLyyMs70SqSkZFBq1atSE9PJygoqDKnJNLoZOUVsnp3Kj/uSCE+MZ3dZTouFXPYbbRr5l8URs0g2iUySAPai4hIlWRkZBAcHHzWvFapFtT8/HzWr1/PfffdV2r7yJEjWbNmTbnvycvLO6Ul1NfXl3Xr1lFQUICnp3n5LzMzk5iYGJxOJ7179+b//u//6NOnz2lrmTNnDg8//HBlyhdp1BL/yOb77Sl8tz2FtXuOkl9miKdAbw+6RAWVtIh2iQyiQ3gAPp4OiyoWEZHGqlIBNTU1FafTSXh46fu3wsPDSU5OLvc9o0aN4r///S/jx4+nb9++rF+/ntdff52CggJSU1OJjIykc+fOLFiwgB49epCRkcFzzz3HsGHD2LhxIx06dCj3uLNmzWLGjBklz4tbUEXEVOh0sSEhje+2H+b7bSnsSindqSg61I8LOjdnSLumJR2XTu7xLiIiYpUqdZIq+0fMMIzT/mF78MEHSU5OZvDgwRiGQXh4ONOmTePxxx/H4TBbZgYPHszgwYNL3jNs2DD69u3LCy+8wPPPP1/ucb29vfH21mVGkZOlZeezYucRvtuWwoqdR0jPOXEPqcNuo39MEy7s0pwLOofTrpm/AqmIiLilSgXUsLAwHA7HKa2lKSkpp7SqFvP19eX111/nlVde4fDhw0RGRjJ//nwCAwMJCwsr9z12u50BAwawa9euypQn0ugYhsGulEy+25bC99sPs37/MVwn3Uoa4ufJ+Z2ac0Hn5pzToRnBfhr3U0RE3F+lAqqXlxf9+vVj+fLlXHHFFSXbly9fzrhx4874Xk9PT1q2bAnA+++/z2WXXYbdXn6PX8MwiI+Pp0ePHpUpT6RRyC1wsvb3o3y/PYXvt6dw4FhOqdc7RwRyQWczlPaJbqKZkkREpN6p9CX+GTNmMGXKFPr378+QIUOYP38+CQkJ3HbbbYB5b+jBgwdZuHAhADt37mTdunUMGjSIY8eO8fTTT7N582befPPNkmM+/PDDDB48mA4dOpCRkcHzzz9PfHw8L730Ug2dpkj9djgjtySQrt6VSk7BiUHxvTzsDGvXlAs6N+f8zs1p2cTPwkpFRESqr9IBdeLEiRw9epTZs2eTlJRE9+7dWbJkCTExMQAkJSWRkJBQsr/T6eSpp55ix44deHp6cv7557NmzRpat25dsk9aWhq33HILycnJBAcH06dPH1auXMnAgQOrf4Yi9ZDLZbDpYHpRKD3M5oMZpV6PCPLh/M7NubBzc4a2b4qflyaFExGRhqPS46C6q4qOqyXirjLzClm9y+zg9MOOI6Rmnhjn12aD3q1CuKBTcy7o0pyukUHq4CQiIvVOrYyDKiI1L/GPbJ76Zgdf/ZZUarD8AG8PzukYxgWdwzmvUzPCAjRqhYiINA4KqCIWScvO58Xvd7Pwp/0lg+a3CfPngqJL9/1bh+LlUXtTh4qIyFkYBrgKoTAPnPnmctr1fHDmFW0rKGe9aL+S9aLXCvNOrBsG2B1gs5tLybqjnO2OMuu28rfb7eUco3jdZq437wLRg8/+86hDCqgidSy3wMmba/bx0g+7ycgtBGB4+zDuHd2ZHi2DLa5ORBo9w4Dso5C2H9ISTizOfPDwAQ/vMo9l18vbp5xHezVnqTMMs6b8LCjIgYLsovXsovXsM6wXvad4PT+76BhF64W5J8InDeJOyDMbcJMCqkhj5XIZfBZ/kKe+2cnBNHNoqM4Rgfzjki6c07GZxdWJSKNhGJD9R1EALRNCi5eC7Nqvw+559hDr8DLD4ukCp+E8++fUJJsdHEV1eXgVrXueqNXhVWbd69T9PYpeK7VetNjs5jm5nGC4zMXlNLeVWjcqud0FLtfpt4d3q9ufYwUooIrUgdW7Unl0yTa2Jpm98SODffjbyE5c0aeFxiltyPKz4d0JZgjwbw7+zSCgmbke0Bz8w05abwa+TcxLbiLVYRiQcwyO7Ss/fKYlmC2FZxMYCSHREBIDIa3A09dsVSxuXTzbY0FOme05ZiAq5iqA/ALIP179c7Z7gqcfePmVfvT0Ay9/s/Zy18vbv+ixvJDpUGyqK/pJi9SirYcy+M/S7azceQSAQG8P/nJ+e24Y1hofz2pe3hL3t+UT2LfKXE9LOPO+AHYPM6j6NzsRWkvWiwJt8bpfU/2xbKyKA+jpWj/TEiA/8+zHKQmgZZcYCG5ptgTWNGdhmSB7lpDrzDNbU8sNnX5m2PTyN1sxpUHRt5tILTiUlsNT3+zkk7gDGAZ4OmxMGdyaOy5oT6i/l9XlSV3Z8Jb5OPBWaHMOZKVAVipkppjrmUcg64i5nptudsY4nmQuZ2UDv9CiFthm5bfQBkZCUAtzP7XM1j3DKHNvZE759zue6d7I8tZz/qhYAA2IOHMA9fSp/Z9BWQ4PcASAd0Ddf7bUKwqoIjUoPaeAeT/u4Y3/7SWv0LyUNbZXFDNHdiK6qWZ4alSO7IDEteY9ZcPvhqDIM+9fmFcUVo8UBdeUoiCbetJ6caBNBYo6smQfhSPbznxshzcERZlhNbjFifWgqBPrfmFmb18xuZyQk2aGwew/zBbLkvXi58dOBM/Tdc6pTQHhpwZPqwOoSA1RQBWpAXmFTt5em8AL3+8iLbsAgEFtQvnHJV3o1SrE2uLEGnFFracdRp09nIJ5OTW4pbmcjctpBtOTQ2txq2xxC23mYbMlNuuIeZn02F5zOR27p1ln2eB68mNAePV7Xtc1w4C842WC5rHSQbO89dz0mq2j5DJ1efdA+p5mvbx7I/3BJ6gogPrWbI0ibkQBVaQaDMPgy01JPL5sO4l/mD3z2zcPYNaYzlzQublme2qsCvNh4/vmet8pNX98u8O8hB/QvAK15JlBNeNQ0XKwzOMhOJ5sdlgpvn/xdGyOotsGygbYk9b9Qot6BheaQdpVeNJS9nlF9qnge/IyIPtY+aHTVVj1n7V3MPg1MTuw+Yaa5+cbWvS8iXmp2tPXDI7ldbQpXtQ6LVIpCqgiVbT296PMWbKNjQfMlpbmgd7MuLgjV/VriYdDf4watZ1LzZbLgHDoMNLaWjy8oUlrczkdZ4EZUssG11IhNskclibjgLnUNx6+ZqD0Cy39WDZ0Fq/7hYJPiDqiiVhE/+WJVNLOw8d57OvtfLc9BQB/Lwe3nduO6SPa4Oel/6SEE5f3e11bP3oXOzzNYYRCWp1+H5fTvHXgdK2wGQcgI8lsiT2ZzWGOTlCy1MZzB3gFnDl06nK4SL2iv6YiFXQ4I5dnlu/kg18TcRngsNu4bmA0d13UgbCAWhiOReqn9IOw+1tzve9Ua2upSXZH0T2qkUC/8vdxucyOQSeHR93mIiJVoIAqchaZeYXMX7GHV1ftJafAnLVkdLcIZo7uRLtmGipFyoh/17wHM2YYNG1ndTV1y27X8EEiUiMUUEVOo8Dp4v11CTz77S6OZuUD0C+mCf+4pDP9YkItrk7ckssFcQvN9T610DlKRKSRUEAVKcMwDJZtSeaxpTvYm2pOB9gmzJ97R3dmVLdw9cyX09u30uwF7x0EXcdZXY2ISL2lgCpSxOUyWLHzCC/+sJv1+48B0NTfi9iLOnDNwGg81TNfzqZ45qgeV5nDDImISJUooEqjl5Pv5JO4A7y+ei97jpgtpr6eDm4e0YZbzm1HgLf+M5EKyP4Dtn1hrjekzlEiIhbQX15ptFIycln4037e+Xk/x4pmfwr09mDigFbcfE5bwoM0TaBUwm8fmjM2hfeAyN5WVyMiUq8poEqjs+VQOq+t3ssXGw9R4DQAaBXqyw1D23B1/5YE+tSDcSvFvRgGbCjqHNV3qoZWEhGpJgVUaRRcLoPvt6fw2uq9/PT70ZLt/WOacNOINlzcNQKHXaFCquhQHBzeDA5v6Hm11dWIiNR7CqjSoGXnF/LxhoO8sXovvxf1yHfYbVzSI5Lpw9vQu1WItQVKw1DcetplrDlzkYiIVIsCqjRIyem5LPxpH+/8nEB6TtH9pT4eXDcwmqlDW9MiRNMeSg3Jz4bNH5vr6hwlIlIjFFClQdl88MT9pYUu8/7SmKZ+3DC0NVf3b4W/euRLTdv6OeRlQEgMtB5hdTUiIg2C/lpLved0GXy37TCvrd7Lz3v/KNk+sE0o04e34aIu4bq/VGpPSeeoKeZUnyIiUm0KqFJvZeUV8tH6A7zxv73sO5oNgIfdxmU9I5k+vC09WgZbXKE0eKm7IWEN2OzQe5LV1YiINBgKqFLvJKXnsGDNPt77OYGM3EIAgnw8mDQ4hqlDYogM1v2lUkfiilpP218MQVHW1iIi0oAooEq9sTExjddW72XJb0kl95e2burHjcPb8Ke+LXV/qdQtZwHEv2eu951ibS0iIg2M/qKLW3O6DJZvPcxrq3/nl33HSrYPbhvKTcPbckHn5th1f6lYYecyyEoB/2bQcbTV1YiINCgKqOKWnC6Dd3/ez6ur9pLwx4n7Sy/vFcWNw9vQvYXuLxWLxb1lPva6FhyafUxEpCYpoIrb2XX4OH//aBMbE9MACPHzZNKgaKYOaU14kI+1xYkAZByCXd+Y6310eV9EpKYpoIrbKHC6mL/yd577dhf5TheB3h78bWRHJg6IxtfLYXV5IifEvwuGC6KHQLOOVlcjItLgKKCKW9hyKJ17PtrElkMZAFzQuTmPXtGDiGC1mIqbcbkg7m1zXa2nIiK1QgFVLJVf6OLF73cx98c9FLoMgn09eejyrozv3QKbTZ2fxA3tXw3H9oJXIHQbb3U1IiINkgKqWGZjYhr3fLSJHYePAzC6WwSzx3ejeaBaTcWNbSjqHNXjT+Dlb20tIiINlAKq1LncAifPfruL+Sv34DKgqb8Xs8d155IeEWo1FfeWcwy2LTbX+0y1thYRkQZMAVXq1Pr9fzDzo038fiQLgMt7RfGvsV1pGuBtcWUiFfDbR1CYC827QYu+VlcjItJgKaBKncjJd/LEsh28sWYvhgHNA715ZHx3RnaLsLo0kYrbUDS1ad8poNZ+EZFao4Aqte6nPUe575NN7D9qDrh/Vb+WPHhpV4L9NLi51COH4iF5Ezi8oOdEq6sREWnQFFCl1mTmFfLY19t5a+1+ACKDfZhzZQ/O69Tc4spEqqB45qjOl4FfqLW1iIg0cAqoUitW7jzCrE9+42BaDgDXDYpm1pjOBPqo1VTqoYIc2PShud5XnaNERGqbAqrUqPScAh79ahuLfk0EoGUTXx77U0+GtQ+zuDKRati6GPLSISQa2pxrdTUiIg2eAqrUmO+3H+Yfn2wmOSMXgGlDWzNzVCf8vfXPTOq54sv7vSeD3W5tLSIijYCSg1Tbsax8Zn+5lU/jDgLQJsyfx/7Uk4FtdJ+eNABH98C+VYAN+kyyuhoRkUZBAVWqZenmJB74bAupmXnYbXDTiLbcfVFHfL0cVpcmUjPi3jYf218IwS2trUVEpJFQQJUqSc3M41+fb+Gr35IAaN88gCeu6kmf6CYWVyZSg5yFEP+uua7OUSIidUYBVSrFMAwWbzzEQ4u3cCy7AIfdxm3ntuXOCzvg7aFWU2lgdi+HzGTwC4OOY6yuRkSk0ajS3f5z586lTZs2+Pj40K9fP1atWnXG/V966SW6dOmCr68vnTp1YuHChafs8/HHH9O1a1e8vb3p2rUrn376aVVKk1qUkpHLLW+t56734zmWXUDniEA+v30YM0d1VjiVhql45qhe14CHl7W1iIg0IpUOqIsWLSI2Npb777+fuLg4RowYwZgxY0hISCh3/3nz5jFr1iweeughtmzZwsMPP8ztt9/OF198UbLPTz/9xMSJE5kyZQobN25kypQpTJgwgZ9//rnqZyY1xjAMPvw1kYueXsHyrYfxdNi4+6KOLL5jON1bBFtdnkjtOJ4MO5eZ67q8LyJSp2yGYRiVecOgQYPo27cv8+bNK9nWpUsXxo8fz5w5c07Zf+jQoQwbNownnniiZFtsbCy//vorq1evBmDixIlkZGTw9ddfl+wzevRomjRpwnvvvVehujIyMggODiY9PZ2goKDKnJKcgctlMOODeD6LPwRAjxbBPHF1TzpH6GcsDdzqZ+Dbh6DlQLhpudXViIg0CBXNa5VqQc3Pz2f9+vWMHDmy1PaRI0eyZs2act+Tl5eHj49PqW2+vr6sW7eOgoICwGxBLXvMUaNGnfaYxcfNyMgotUjNMgyD2V9u5bP4Q3g6bNwzuhOf/mWowqk0fIYBG4rGPlXrqYhInatUQE1NTcXpdBIeHl5qe3h4OMnJyeW+Z9SoUfz3v/9l/fr1GIbBr7/+yuuvv05BQQGpqakAJCcnV+qYAHPmzCE4OLhkadWqVWVORSpg3oo9LFizD4CnJ/TmL+e1x8OhQcqlEdi/Bv7YA14B0O0Kq6sREWl0qpQ2bDZbqeeGYZyyrdiDDz7ImDFjGDx4MJ6enowbN45p06YB4HCc6FhTmWMCzJo1i/T09JIlMTGxKqcip/Hhr4k8vnQHAP+8rCtje0VZXJFIHSruHNX9SvAOsLYWEZFGqFIBNSwsDIfDcUrLZkpKyiktoMV8fX15/fXXyc7OZt++fSQkJNC6dWsCAwMJCzPnZ4+IiKjUMQG8vb0JCgoqtUjN+GFHCvd98hsAt57blhuHt6n7IjKPwGuj4MMboCC37j9fGq+cNNj6ubneR5f3RUSsUKmA6uXlRb9+/Vi+vHSHgeXLlzN06NAzvtfT05OWLVvicDh4//33ueyyy7AXzWk9ZMiQU475zTffnPWYUvPiEo7xl7c34HQZXNm3BfeN7lz3RTgL4aMbIHEtbPkEPp5ubhOpC5s/gsIcaNYFWva3uhoRkUap0gP1z5gxgylTptC/f3+GDBnC/PnzSUhI4LbbbgPMS+8HDx4sGet0586drFu3jkGDBnHs2DGefvppNm/ezJtvvllyzLvuuotzzjmHxx57jHHjxvH555/z7bfflvTyl7rx+5FMblzwCzkFTs7p2IzH/tTzjLdZ1Jrv/8+c+9zTH1yFsP1L+DIWLn8BrKhHGpeSzlFT9O9NRMQilQ6oEydO5OjRo8yePZukpCS6d+/OkiVLiImJASApKanUmKhOp5OnnnqKHTt24Onpyfnnn8+aNWto3bp1yT5Dhw7l/fff54EHHuDBBx+kXbt2LFq0iEGDBlX/DKVCUjJymfr6Oo5lF9CzZTDzJvXF04oOUVsXw/+eNdfHvwR2D/hgKsS9Bf5hcNFDdV+TNB5JmyApHuye0PMaq6sREWm0Kj0OqrvSOKhVl5FbwMRX1rItKYPWTf346M9DCQvwrvtCUnfB/PMh/zgMuQNG/dvcvv5N+OJOc33kv2HoHXVfm9SctATY/S10ugQCI6yuprQlM2HdfOg6Hia8edbdRUSkcmplHFRpePIKndy6cD3bkjIIC/Bm4Y2DrAmneZmwaLIZTmOGw0UPn3it3/Vw4T/N9W/uh/iKTd4gbsQwYM8P8N518Fwv+PJueHk47F1pdWUnFOTApkXmet8p1tYiItLIVfoSvzQc5ixRG/np96MEeHuw4IYBRDf1q/tCDAMW3wFHtkNgJFz9BjjK/NMcPgOyjsLal+Dz28EvFDqOqvtapXLyjsPG981WydSdJ7b7N4OsI7BwHFzwIAyLBbvF/7+87UvITYfgVtD2fGtrERFp5NSC2kgVzxL11aYkPB02Xp7cj+4tgq0pZu1c2PKpeb/p1W9CQPNT97HZYOQj0HMiGE744HpIWFv3tUrFpO6CJffAU11gyd/NcOoVAANuhtvXQexv0HsSGC747mFYNMkc3slKcUVjn/aeBHbHmfcVEZFapRbURurlFb+XzBL11ITeDO8QZk0h+/4H3zxoro+aA9Fn6Bhnt8O4lyDnGOz6Bt6dADd8DeHd6qZWOTOXE3YuM1tLf//hxPamHWDgLdDrGvA56X6jcS9Bq0HmfZ87lsD882DCQojsWeel88fvRbcb2KDPpLr/fBERKUUtqI3QR+sP8NjS7QA8eFlXLrdqlqiMJPhwmtki2mMCDLz57O9xeJqtrK0GmZdj37oSju2r7UrlTLL/gP89B8/3hvevLQqnNrMT1JRPzRbTQbeUDqdgtor3ux6mL4OQaDi2F167GOLeqftzKP7MduebtYiIiKUUUBuZH3akcO/HmwC49Zy2TLdiliiAwnz48HrISoHm3WDssxUfc9LLD65bBM27QmYyvHWFOfOU1K2kTfD5HfB0F1j+T7N3vk8IDL0T7oqHa9+Ddhec/d7SqD5wywroMBIKc+Hzv8DiO+tuBjFnIcS/a673UecoERF3oIDaiMQnppXMEnVFnxbca8UsUcWWPwiJP4N3MEx8C7z8K/d+3yYw+WMIjjYvz759JeRm1E6tcoKzADZ/bE5D+8oIc3zawlwI72FOpDBjG4z8P2jSunLH9QuFaxfB+Q8ANtjwJrw+sm5ax/d8B8cPgW8odL609j9PRETOSgG1kSg7S9TjV/XEbrdolpxNH8LPL5vrV7wMTdtV7ThBUeYlZL8wSN4E719Xd61ujc3xw/Djf+CZ7vDRjeY0tHYP6P4nuHEZ3LYK+k41W7erym6Hc2fClE/MsJi0EV45F3Z+U3PnUZ4NRZ2jel0DHhYMsSYiIqdQQG0EimeJ+iMr39pZogAObzkx6P6Iv0PnS6p3vLD2MPkj8Ao0p0f9eLrZWUeqzzAg4Wf4aDo80w1+nGPeUhEQDufeB7Gb4arXIXpwzU4J2u4CuHUltOgHuWnw7tXw/b9r5/eamQI7l5rrurwvIuI2FFAbuIzcAq5/4xcOHMuhdVM/Xp82AH9viwZvyE03B+MvyDbHmTz/HzVz3Kg+cO274PCC7V/Cl7FmuJKqKciBuLdh/rnmZfbNH4GrwOyY9qfXzGB6/iwIiqy9GkJamSM0DCjqOLfycXj7T+ZYuDVp43vgKoQW/SG8a80eW0REqkzDTDVgeYVObnureJYoL+tmiQJwueDTP5v3iwa3MoNOTY412eYc85gfXm9esvVvdmL2KamYY/vh19fMn1/OMXObhw/0uMoMilG967YeD2+49EkzGH9xpzk6wCsjikZxGFD94xsGbHjLXO87tfrHExGRGqOA2kAVzxK1Zs9R/L0cLLhhoDWzRBX73zOw4yuzlXPCQvBvWvOf0fVyuOwZ+OIuWPWUeW/qkL/U/Oc0JIYBv/8I616FnV+bA+eD2flswHQzuPmFWloiPa+GiO5m6/vR3fDGGBg9BwbcVL1bCxLWwtFd4OkP3a+suXpFRKTaFFAboFNmiZpi4SxRAHu+h+8fMdcveRJa9K29z+o3DbJS4fv/g2WzwK8p9JpYe59XHxkGHNoA276ArYvhjz0nXmt7njmofsfR7jWbUvMucPMP5pS4Wz83Z6dK/BnGPlf5ESCKxRW1nna7ArwDa65WERGpNgXUBujkWaKevLoXIzo0s66YtESzk43hMjuh9Lu+9j9zxN/MkPrzPHNMTd8m0HFk7X+uO3MWQsJPZijd/iVkHDzxmlcA9LrWnCihWSfrajwbnyDz8v7auebsY799CMmbzWHKwjpU7li5Geb0uqDL+yIibkgBtYE5eZaoBy7twrjeLawrpiAXPpgCOX9AZG+z9bQu2Gww6lHIPgq/fQAfTIWpn595GtWGqCDXvHy//QvYvsT8PRTz9DdDe+fLoOOo+tOCaLPBkNvNjnEf3gBHtplTpI57CbqNr/hxNn9sdtYL6witBtZWtSIiUkUKqA3IybNE3XJOW24a0dbagpbeC4fizBbMiW+Bp0/dfbbdDuPnmp19di83hyq6YWnD76mddxx2fWO2lO5aDvmZJ17zDTWnH+0y1ryUX5e/j5oWM9QciuqjG2H/arNzXOLtcPHD5nS4Z1M89mnfqTU7RJaIiNQIm2E0jPF4MjIyCA4OJj09naCgoLO/oYGJT0zj2vlrySlwMr53FE9P6G3dQPxg9o5efAdgM2d8an+hNXXkZ8HC8XBgHQRGmoPKN4mxppbakpUKO5bAti/Nnu7O/BOvBUZBl8vMUBo9FBwN7P9JnYXw/Wz433Pm81aD4eoFZx4C6/AWmDfUnGhgxnYIsPAWGBGRRqaiea2B/bVqnE6eJWpEhzAev6qXteH0UDx89Tdz/YL7rQunYHaguW4RvHGJeTn4rSvMkFrfQ0n6ATOQbv8S9v/vRO97gKbtzUDaeax5KdzegIc7dnjAxbOh5UD47M/mDFevjICr3oA2I8p/T/HQUp0uqf//DkREGigF1Hou5fiJWaJ6tAhm3uR+eHlYGEiy/4BFU8CZBx3HwPC/WVdLMb9Qc/rM10aZPdbf+RNc/6XZ6aY+ObLTvJ902xfmrRMni+gJXS43g2mzTo3vsnWXy8ye/h9MhcObYeHl5ji4w2JL/ywK82DT++a6OkeJiLgtBdR67HhuAdNeN2eJimnqxxs3DCDAqlmiwJyK8uObID0BmrSBK152n9a7oCiY8qk5M1LSRlg0Ca770L3vwzQMSIo3A+m2LyF1x0kv2iB6iBnMOl/W8G5bqIqm7WD6cvhqhjlD1LcPQeIv5r3IviHmPtu/NO9LDmphTqkqIiJuSQG1nsordHLrW+vZWjJL1EDrZokq9uN/YM934OELE98+EQrcRVh7837YBZfB3pXwyc3m/YruNN6ny2kOIF88HFR64onX7J7Q9lwzkHa+FAKaW1enu/Lyg/HzzNmnvr7HnBxi/nlmJ72IHic6R/We5F6/dxERKUUBtR5yuQz+dtIsUW9MG0hM0yoOVl5Tdiw150sHc/D0iO7W1nM6UX3gmnfhnatg22Kzte2yZ627JO5ywbG95iX7vSvM4aCyU0+87ukH7S8yL993HAk+Fk64UF/YbND/BojsBR9cb/58/3sRnHuPOewWQJ9JlpYoIiJnpoBazxiGwf99tZUvNyXhYTdnierR0uLQcnQPfHKLuT7wFvefuantuXDlq/DhNFi/APybwQUP1P7nulzmPbCH4s1L94fiIXkT5GWU3s8nBDqNMe8nbXcBePrWfm0NUYu+cOsKs6V897fw3Wxze9vzoElrKysTEZGzUECtZ15Z+Ttv/G8f4AazRAHkZ5sdU/LSzZ7UI/9tbT0V1W085DwNX94NK58AvzAYfFvNHd/lNOeNLxtGTx6XtJiHD4R3hxb9zGDaenjFxvKUs/MLNe81XvkE/DgHMNQ5SkSkHlBArUdW7jzCf74+MUvU+D4WzhIFZieeL2PNXtP+zWDCm+DhZW1NldH/Rsg6Cj88Yk4q4BcKPSdU/jguJ6TuLBNGf4OCrFP39fA174WM7AVRvc0Ztpp1UiCtTXY7nHev2XJ6dDd0u9LqikRE5CwUUOuRrzYlAfCnvi2tnyUK4Jf/wqZFYHOY404GRVldUeWd83fzns+fXzbH0fRtAh0uPv3+zkKzN/3JYfTwZnPazLI8/YrCaO8TYTSsY8MbLL++iB7U+Ka7FRGpp/SXsh7ZkHAMgFHdwi2uBEhcB0tnmesXP3z6QdHdnc0Go+ZA9lH47UNzDNfrF5vzszsL4Mj2U8NoYe6px/H0h8ieZcJoB/UUFxERqQIF1HoiPbuAXSnm/Yt9Y5pYW0xminnfqasAuo6DIXdYW0912e0wbq45Pubub80e/qHtzCkxnXmn7u8VeGoYbdpOYVRERKSGKKDWE3GJZutpTFM/a8c7dRbCRzfC8STzcvW4lxrGrEUeXjBhISwcBwd+gUMbzO3eQeb9opG9zCGqIntDaFv3mYBARESkAVJArSc27DcDar9oi1tPv3sY9q0CrwBzMH7vQGvrqUle/jDpI4h7CwIjzUDapI3CqIiISB1TQK0nNiSkAdDHysv7Wz+HNc+b6+NeMnufNzS+ITD0r1ZXISIi0qipaagecLoM4hPTAOgbHWJNEUd2wmd/MdeH3mmOIyoiIiJSCxRQ64Gdh4+TmVeIv5eDTuEWXFLPOw6LJpuDzLceARf+q+5rEBERkUZDAbUeKB5eqlerEDwcdfwry0kze+yn7oDAKLjqdY3jKSIiIrVKSaMeWF/cQaqu7z89vAXenwTH9prTcU54EwKa120NIiIi0ugooNYDcUUdpPrWZQ/+3z6CxX81Z0gKiTZ77Ef2qrvPFxERkUZLAdXNHc3MY2+qOad7n7roIOUsgOX/grUvmc/bXQB/es2cp15ERESkDiigurni1tN2zfwJ8fOq3Q/LTIEPb4D9q83nw2fABQ9ohiQRERGpUwqobq64g1StX94/8Ks5D/3xQ+ZUnlfMgy5ja/czRURERMqhgOrmar2DlGHA+gXw9T3gzDenL534DjTrWDufJyIiInIWCqhurMDpYtOBdAD61kZALciFJX83p/YEs8V0/LyGNX2piIiI1DsKqG5se9JxcgqcBPp40L5ZQM0ePC0RPpgCh+LAZocL/wnDYsFmq9nPEREREakkBVQ3Vnz/aZ/oJtjtNRgcf/8RProRso+Cbyhc9ZrZW19ERETEDSigurHigNqvpjpIGQaseR6+fQgMlzmu6cS3zXFORURERNyEAqobK+4g1TcmpPoHyzsOn98BWz8zn/eeBJc+BZ6+1T+2iIiISA1SQHVTKRm5HDiWg80GvVuFVO9gqbth0SQ4sh3snjDmMeh/o+43FREREbekgOqmii/vdwoPJNDHs+oH2v4VfHob5GVAYCRMWAitBtZQlSIiIiI1z16VN82dO5c2bdrg4+NDv379WLVq1Rn3f+edd+jVqxd+fn5ERkZyww03cPTo0ZLXFyxYgM1mO2XJzc2tSnkNwoaiGaT6VPX+U5cTvn8E3r/ODKfRQ+GWFQqnIiIi4vYqHVAXLVpEbGws999/P3FxcYwYMYIxY8aQkJBQ7v6rV69m6tSpTJ8+nS1btvDhhx/yyy+/cNNNN5XaLygoiKSkpFKLj49P1c6qAajWAP3Zf8C7E2DlE+bzQX+G6xdDYHgNVigiIiJSOyodUJ9++mmmT5/OTTfdRJcuXXj22Wdp1aoV8+bNK3f/tWvX0rp1a+68807atGnD8OHDufXWW/n1119L7Wez2YiIiCi1NFb5hS5+O1g0QH90SOXenLQJ5p8Hu78FD1+48lUY8x9wVOM2AREREZE6VKmAmp+fz/r16xk5cmSp7SNHjmTNmjXlvmfo0KEcOHCAJUuWYBgGhw8f5qOPPuLSSy8ttV9mZiYxMTG0bNmSyy67jLi4uDPWkpeXR0ZGRqmlodhyKJ38QhdN/DxpE+Zf8TduXASvjYS0/dCkNdy0HHpOqLU6RURERGpDpQJqamoqTqeT8PDSl4rDw8NJTk4u9z1Dhw7lnXfeYeLEiXh5eREREUFISAgvvPBCyT6dO3dmwYIFLF68mPfeew8fHx+GDRvGrl27TlvLnDlzCA4OLllatWpVmVNxayXDS0U3wVaRnvbOAlhyD3x6CxTmQPuL4ZYfIaJH7RYqIiIiUguq1EmqbGgyDOO0QWrr1q3ceeed/POf/2T9+vUsXbqUvXv3ctttt5XsM3jwYCZPnkyvXr0YMWIEH3zwAR07diwVYsuaNWsW6enpJUtiYmJVTsUtxRV1kOpbkftPjx+GN8fCulfM5+feC9d9AL41NLi/iIiISB2r1DBTYWFhOByOU1pLU1JSTmlVLTZnzhyGDRvGzJkzAejZsyf+/v6MGDGCRx55hMjIyFPeY7fbGTBgwBlbUL29vfH29q5M+fXGyS2oZ5TwM3wwFTKTwTsIrpwPncbUQYUiIiIitadSLaheXl7069eP5cuXl9q+fPlyhg4dWu57srOzsdtLf4zD4QDMltfyGIZBfHx8ueG1oTuUlkNyRi4Ou41erYLL38kwYN2rsOBSM5w262Je0lc4FRERkQag0gP1z5gxgylTptC/f3+GDBnC/PnzSUhIKLlkP2vWLA4ePMjChQsBGDt2LDfffDPz5s1j1KhRJCUlERsby8CBA4mKigLg4YcfZvDgwXTo0IGMjAyef/554uPjeemll2rwVOuH4tbTLpGB+HmV8+spyIEvZ8DGd83n3a6Ay18E74A6rFJERESk9lQ6oE6cOJGjR48ye/ZskpKS6N69O0uWLCEmJgaApKSkUmOiTps2jePHj/Piiy/yt7/9jZCQEC644AIee+yxkn3S0tK45ZZbSE5OJjg4mD59+rBy5UoGDmx8g8oXzyBV7uX9jCRzfNPkTWBzwMUPw5A7NGWpiIiINCg243TX2euZjIwMgoODSU9PJygoyOpyqmzcS/9jY2Iaz13Tm3G9W5x4oTAP3rgEDv4KfmFw9RvQ5hzrChURERGppIrmtUq3oErtyS1wsqVkgP4yLajL/mGGU58QmP4NNG1X9wWKiIiI1IEqDTMlteO3g+kUugzCArxp2cT3xAsb34df/gvYzJmhFE5FRESkAVNAdSPFHaT6xYScGFc2eTN8EWuun3sPdBxZ/ptFREREGggFVDeyoez4pzlpsGiyOTtUuwvNQfhFREREGjgFVDdhGAYbimaQ6hfTBFwu+OzPcGwvBEfDn/4Ldoe1RYqIiIjUAQVUN5H4Rw6pmXl4Omx0bxEM/3sGdiwBhzdMXAh+oVaXKCIiIlInFFDdRPH4p92igvFJWAnfP2K+cMkTENXHwspERERE6pYCqpso7iB1XkQ+fDwdDBf0mQz9rre4MhEREZG6pYDqJjYkHMOLAq4/8E/IPgqRveCSJ60uS0RERKTOKaC6gay8QrYlZfCgx1s0ObbJHIx/wkLw9D3re0VEREQaGgVUN7DxQBrjbSuZ4vEtYDN77DdpbXVZIiIiIpZQQHUDCVvX8ajna+aTc++FDhdbW5CIiIiIhRRQrZaTxvkb/4aPrYDEpsM0GL+IiIg0egqoVnK5MD69lfDCQyS6mpE2Zi7Y9SsRERGRxk1pyEqrn8K2cyl5hid3umbQqXW01RWJiIiIWE4B1Sp7vofv/w3Ag4XTcLTojZeHfh0iIiIiSkRWSEuEj6YDButCx/KB83z6xTSxuioRERERt6CAWtcK8+CDqZDzB0T2ZnbhNAD6RCugioiIiIACat37+l44tAF8m3B83OtsOZIHQN+YEGvrEhEREXETCqh1Kf5dWP8GYIMr/0tcRhCGAa1CfWke6GN1dSIiIiJuQQG1riRtgi/vNtfPmwUdLmJDwjEA+unyvoiIiEgJBdS6kHMMPpgChbnQYSScMxOA9fvNgNpXHaRERERESiig1jaXCz65FY7tg5BouOIVsNtxuQziE9MA6KsWVBEREZESCqi1bdVTsGsZOLxhwlvgFwrA7iOZHM8txNfTQeeIQIuLFBEREXEfCqi1afd38IM5GD+XPQ1RvUteKr6836tVMB4O/RpEREREiikZ1Za0BPj4JsCAvtdDn8mlXt5QFFA1QL+IiIhIaQqotaEgt9Rg/Ix5/JRd1hf14Nf9pyIiIiKlKaDWhqX3wqE48G0CE98Cz9JjnB7Lyuf3I1mAZpASERERKUsBtabFvQPrFwA2+NN/zZ77ZXdJNFtP24b5E+rvVbf1iYiIiLg5BdSalLQJvpphrp//D2h/Ubm7bdifBqj1VERERKQ8Cqg1JecYLJpcNBj/KBjx99PuWjKDlDpIiYiIiJxCAbUmuFzwyS2Qth9CYuBKczD+8hQ6XScG6I8JqbsaRUREROoJBdSasOpJ2PUNePiYnaJ8T98yuuPwcbLznQR6e9ChuQboFxERESlLAbW6dn8LPzxqrl/6NET2OuPuxeOf9o4OwWG31XZ1IiIiIvWOAmp1HNt/YjD+ftOgz6SzvmVDQhqg8U9FRERETkcBtapKBuM/BlF9YPRjFXpbcQepvuogJSIiIlIuBdSq+voeSIoH31CYsPCUwfjLk5qZx/6j2QD0bhVSu/WJiIiI1FMKqFWx/SvY8CZnGoy/PMX3n3YMDyDY17MWCxQRERGpvzysLqBe6jASBv/FbD1tf2GF37a++PK+7j8VEREROS0F1KpweMLoOWAYlXpbXNEMUrr/VEREROT0dIm/OmwVHyYqv9DFxgNpgFpQRURERM5EAbWObEvKIK/QRYifJ23D/K0uR0RERMRtKaDWkeLhpfq0CsGuAfpFRERETksBtY6s368OUiIiIiIVoYBaR+KKZpDqpw5SIiIiImekgFoHktNzOZiWg90GvTRAv4iIiMgZKaDWgeL7TztHBOHvrZG9RERERM6kSgF17ty5tGnTBh8fH/r168eqVavOuP8777xDr1698PPzIzIykhtuuIGjR4+W2ufjjz+ma9eueHt707VrVz799NOqlOaWimeQ6hsTYm0hIiIiIvVApQPqokWLiI2N5f777ycuLo4RI0YwZswYEhISyt1/9erVTJ06lenTp7NlyxY+/PBDfvnlF2666aaSfX766ScmTpzIlClT2LhxI1OmTGHChAn8/PPPVT8zN1I8g5TuPxURERE5O5thVG46pEGDBtG3b1/mzZtXsq1Lly6MHz+eOXPmnLL/k08+ybx589izZ0/JthdeeIHHH3+cxMREACZOnEhGRgZff/11yT6jR4+mSZMmvPfeexWqKyMjg+DgYNLT0wkKCqrMKdWq3AInPR/6hnynixUzzyOmqcZAFRERkcaponmtUi2o+fn5rF+/npEjR5baPnLkSNasWVPue4YOHcqBAwdYsmQJhmFw+PBhPvroIy699NKSfX766adTjjlq1KjTHhMgLy+PjIyMUos72nIonXyni6b+XkSH+lldjoiIiIjbq1RATU1Nxel0Eh4eXmp7eHg4ycnJ5b5n6NChvPPOO0ycOBEvLy8iIiIICQnhhRdeKNknOTm5UscEmDNnDsHBwSVLq1atKnMqdWbD/jQA+sY0wVaJqVFFREREGqsqdZIqG7QMwzht+Nq6dSt33nkn//znP1m/fj1Lly5l79693HbbbVU+JsCsWbNIT08vWYpvF3A3GqBfREREpHIqNeZRWFgYDofjlJbNlJSUU1pAi82ZM4dhw4Yxc+ZMAHr27Im/vz8jRozgkUceITIykoiIiEodE8Db2xtvb+/KlF/nDMMoGWJKHaREREREKqZSLaheXl7069eP5cuXl9q+fPlyhg4dWu57srOzsdtLf4zD4QDMAAcwZMiQU475zTffnPaY9cXBtBxSjufhYbfRs2Ww1eWIiIiI1AuVHjV+xowZTJkyhf79+zNkyBDmz59PQkJCySX7WbNmcfDgQRYuXAjA2LFjufnmm5k3bx6jRo0iKSmJ2NhYBg4cSFRUFAB33XUX55xzDo899hjjxo3j888/59tvv2X16tU1eKp1r/jyfreoIHw8HRZXIyIiIlI/VDqgTpw4kaNHjzJ79mySkpLo3r07S5YsISYmBoCkpKRSY6JOmzaN48eP8+KLL/K3v/2NkJAQLrjgAh577LGSfYYOHcr777/PAw88wIMPPki7du1YtGgRgwYNqoFTtE5cQhoAfXT/qYiIiEiFVXocVHfljuOgjn1hNb8dTOf5a/twea8oq8sRERERsVStjIMqFZedX8jWJHNsVnWQEhEREak4BdRasulAOk6XQXiQN1HBPlaXIyIiIlJvKKDWkpOHl9IA/SIiIiIVp4BaS0pmkFIHKREREZFKUUCtBScP0N9X95+KiIiIVIoCai3YfzSbP7Ly8XLY6RblHiMKiIiIiNQXCqi1oHiA/u4tgvD20AD9IiIiIpWhgFoLTu4gJSIiIiKVo4BaCzYUzSClDlIiIiIilaeAWsMy8wrZkWwO0K8OUiIiIiKVp4BawzYmpuEyoEWIL+FBGqBfREREpLIUUGtYcQcp3X8qIiIiUjUKqDWsZPzT6BBrCxERERGppxRQa5DLZbBhvwboFxEREakOBdQa9HtqJhm5hfh42ukSqQH6RURERKpCAbUGbdifBkDPliF4OvSjFREREakKpagapA5SIiIiItWngFqDTnSQUkAVERERqSoF1BqSnl3ArpRMQD34RURERKpDAbWGxCWaraetm/rRNMDb4mpERERE6i8F1BqyISEN0OV9ERERkepSQK0hGv9UREREpGYooNYAp8sgPjENUAuqiIiISHUpoNaAnYePk5lXiL+Xg04RgVaXIyIiIlKvKaDWgOLhpXpHh+Cw2yyuRkRERKR+U0CtASUD9OvyvoiIiEi1KaDWgLiiHvx91EFKREREpNoUUKvpj6x89qZmAdC3lQKqiIiISHUpoFZT8fBS7ZsHEOznaXE1IiIiIvWfAmo1FXeQ0vSmIiIiIjVDAbWaSjpI6f5TERERkRqhgFoNhU4Xmw6kAxqgX0RERKSmKKBWw/bk4+QUOAny8aBdswCryxERERFpEBRQq6H48n6f6CbYNUC/iIiISI1QQK2GEx2kdHlfREREpKYooFaDOkiJiIiI1DwF1CpKycjlwLEcbDbo1SrY6nJEREREGgwF1CoqvrzfKTyQQB8N0C8iIiJSUxRQq2hDQhoAfXV5X0RERKRGKaBWUfEUp/3UQUpERESkRimgVkF+oYtNB4sG6FcLqoiIiEiNUkCtgi2H0skvdBHq70Xrpn5WlyMiIiLSoHhYXUB91CUyiHdvHsTRzHxsNg3QLyIiIlKTFFCrwMfTwdB2YVaXISIiItIg6RK/iIiIiLgVBVQRERERcSsKqCIiIiLiVqoUUOfOnUubNm3w8fGhX79+rFq16rT7Tps2DZvNdsrSrVu3kn0WLFhQ7j65ublVKU9ERERE6rFKB9RFixYRGxvL/fffT1xcHCNGjGDMmDEkJCSUu/9zzz1HUlJSyZKYmEhoaChXX311qf2CgoJK7ZeUlISPj0/VzkpERERE6q1KB9Snn36a6dOnc9NNN9GlSxeeffZZWrVqxbx588rdPzg4mIiIiJLl119/5dixY9xwww2l9rPZbKX2i4iIqNoZiYiIiEi9VqmAmp+fz/r16xk5cmSp7SNHjmTNmjUVOsZrr73GRRddRExMTKntmZmZxMTE0LJlSy677DLi4uLOeJy8vDwyMjJKLSIiIiJS/1UqoKampuJ0OgkPDy+1PTw8nOTk5LO+Pykpia+//pqbbrqp1PbOnTuzYMECFi9ezHvvvYePjw/Dhg1j165dpz3WnDlzCA4OLllatWpVmVMRERERETdVpU5SZWdPMgyjQjMqLViwgJCQEMaPH19q++DBg5k8eTK9evVixIgRfPDBB3Ts2JEXXnjhtMeaNWsW6enpJUtiYmJVTkVERERE3EylZpIKCwvD4XCc0lqakpJySqtqWYZh8PrrrzNlyhS8vLzOuK/dbmfAgAFnbEH19vbG29u74sWLiIiISL1QqYDq5eVFv379WL58OVdccUXJ9uXLlzNu3LgzvnfFihXs3r2b6dOnn/VzDMMgPj6eHj16VLg2wzAAdC+qiIiIiJsqzmnFue20jEp6//33DU9PT+O1114ztm7dasTGxhr+/v7Gvn37DMMwjPvuu8+YMmXKKe+bPHmyMWjQoHKP+dBDDxlLly419uzZY8TFxRk33HCD4eHhYfz8888VrisxMdEAtGjRokWLFi1atLj5kpiYeMZcV6kWVICJEydy9OhRZs+eTVJSEt27d2fJkiUlvfKTkpJOGRM1PT2djz/+mOeee67cY6alpXHLLbeQnJxMcHAwffr0YeXKlQwcOLDCdUVFRZGYmEhgYGCF7oetroyMDFq1akViYiJBQUG1/nlWakznCo3rfHWuDVdjOl+da8PVmM63sZyrYRgcP36cqKioM+5nM4yztbFKeTIyMggODiY9Pb1B/0OCxnWu0LjOV+facDWm89W5NlyN6Xwb07lWRJV68YuIiIiI1BYFVBERERFxKwqoVeTt7c2//vWvRjHUVWM6V2hc56tzbbga0/nqXBuuxnS+jelcK0L3oIqIiIiIW1ELqoiIiIi4FQVUEREREXErCqgiIiIi4lYUUEVERETErSigioiIiIhbUUCtgrlz59KmTRt8fHzo168fq1atsrqkWjFnzhwGDBhAYGAgzZs3Z/z48ezYscPqsurEnDlzsNlsxMbGWl1KrTh48CCTJ0+madOm+Pn50bt3b9avX291WbWisLCQBx54gDZt2uDr60vbtm2ZPXs2LpfL6tKqbeXKlYwdO5aoqChsNhufffZZqdcNw+Chhx4iKioKX19fzjvvPLZs2WJNsTXgTOdbUFDAvffeS48ePfD39ycqKoqpU6dy6NAh6wquhrP9bk926623YrPZePbZZ+usvppUkXPdtm0bl19+OcHBwQQGBjJ48OBTplWvL852vpmZmdxxxx20bNkSX19funTpwrx586wp1kIKqJW0aNEiYmNjuf/++4mLi2PEiBGMGTOm3v6HciYrVqzg9ttvZ+3atSxfvpzCwkJGjhxJVlaW1aXVql9++YX58+fTs2dPq0upFceOHWPYsGF4enry9ddfs3XrVp566ilCQkKsLq1WPPbYY7z88su8+OKLbNu2jccff5wnnniCF154werSqi0rK4tevXrx4osvlvv6448/ztNPP82LL77IL7/8QkREBBdffDHHjx+v40prxpnONzs7mw0bNvDggw+yYcMGPvnkE3bu3Mnll19uQaXVd7bfbbHPPvuMn3/++azzmruzs53rnj17GD58OJ07d+bHH39k48aNPPjgg/j4+NRxpTXjbOd79913s3TpUt5++222bdvG3XffzV//+lc+//zzOq7UYoZUysCBA43bbrut1LbOnTsb9913n0UV1Z2UlBQDMFasWGF1KbXm+PHjRocOHYzly5cb5557rnHXXXdZXVKNu/fee43hw4dbXUadufTSS40bb7yx1LYrr7zSmDx5skUV1Q7A+PTTT0ueu1wuIyIiwvjPf/5Tsi03N9cIDg42Xn75ZQsqrFllz7c869atMwBj//79dVNULTnduR44cMBo0aKFsXnzZiMmJsZ45pln6ry2mlbeuU6cOLHB/fdarLzz7datmzF79uxS2/r27Ws88MADdViZ9dSCWgn5+fmsX7+ekSNHlto+cuRI1qxZY1FVdSc9PR2A0NBQiyupPbfffjuXXnopF110kdWl1JrFixfTv39/rr76apo3b06fPn149dVXrS6r1gwfPpzvvvuOnTt3ArBx40ZWr17NJZdcYnFltWvv3r0kJyeX+r7y9vbm3HPPbRTfV2B+Z9lstgZ5dcDlcjFlyhRmzpxJt27drC6n1rhcLr766is6duzIqFGjaN68OYMGDTrjLQ/13fDhw1m8eDEHDx7EMAx++OEHdu7cyahRo6wurU4poFZCamoqTqeT8PDwUtvDw8NJTk62qKq6YRgGM2bMYPjw4XTv3t3qcmrF+++/z4YNG5gzZ47VpdSq33//nXnz5tGhQweWLVvGbbfdxp133snChQutLq1W3HvvvVx77bV07twZT09P+vTpQ2xsLNdee63VpdWq4u+kxvh9BZCbm8t9993HddddR1BQkNXl1LjHHnsMDw8P7rzzTqtLqVUpKSlkZmbyn//8h9GjR/PNN99wxRVXcOWVV7JixQqry6sVzz//PF27dqVly5Z4eXkxevRo5s6dy/Dhw60urU55WF1AfWSz2Uo9NwzjlG0NzR133MGmTZtYvXq11aXUisTERO666y6++eabentfU0W5XC769+/Po48+CkCfPn3YsmUL8+bNY+rUqRZXV/MWLVrE22+/zbvvvku3bt2Ij48nNjaWqKgorr/+eqvLq3WN8fuqoKCAa665BpfLxdy5c60up8atX7+e5557jg0bNjT432VxZ8Zx48Zx9913A9C7d2/WrFnDyy+/zLnnnmtlebXi+eefZ+3atSxevJiYmBhWrlzJX/7yFyIjIxv01b2yFFArISwsDIfDcUrrQ0pKyimtFA3JX//6VxYvXszKlStp2bKl1eXUivXr15OSkkK/fv1KtjmdTlauXMmLL75IXl4eDofDwgprTmRkJF27di21rUuXLnz88ccWVVS7Zs6cyX333cc111wDQI8ePdi/fz9z5sxp0AE1IiICMFtSIyMjS7Y39O+rgoICJkyYwN69e/n+++8bZOvpqlWrSElJITo6umSb0+nkb3/7G88++yz79u2zrrgaFhYWhoeHR7nfWQ2xwSQnJ4d//OMffPrpp1x66aUA9OzZk/j4eJ588slGFVB1ib8SvLy86NevH8uXLy+1ffny5QwdOtSiqmqPYRjccccdfPLJJ3z//fe0adPG6pJqzYUXXshvv/1GfHx8ydK/f38mTZpEfHx8gwmnAMOGDTtluLCdO3cSExNjUUW1Kzs7G7u99Fedw+FoEMNMnUmbNm2IiIgo9X2Vn5/PihUrGuT3FZwIp7t27eLbb7+ladOmVpdUK6ZMmcKmTZtKfV9FRUUxc+ZMli1bZnV5NcrLy4sBAwY0mu+sgoICCgoKGuV3VllqQa2kGTNmMGXKFPr378+QIUOYP38+CQkJ3HbbbVaXVuNuv/123n33XT7//HMCAwNLWo6Dg4Px9fW1uLqaFRgYeMq9tf7+/jRt2rTB3XN79913M3ToUB599FEmTJjAunXrmD9/PvPnz7e6tFoxduxY/v3vfxMdHU23bt2Ii4vj6aef5sYbb7S6tGrLzMxk9+7dJc/37t1LfHw8oaGhREdHExsby6OPPkqHDh3o0KEDjz76KH5+flx33XUWVl11ZzrfqKgorrrqKjZs2MCXX36J0+ks+c4KDQ3Fy8vLqrKr5Gy/27Lh29PTk4iICDp16lTXpVbb2c515syZTJw4kXPOOYfzzz+fpUuX8sUXX/Djjz9aV3Q1nO18zz33XGbOnImvry8xMTGsWLGChQsX8vTTT1tYtQUsHUOgnnrppZeMmJgYw8vLy+jbt2+DHXYJKHd54403rC6tTjTUYaYMwzC++OILo3v37oa3t7fRuXNnY/78+VaXVGsyMjKMu+66y4iOjjZ8fHyMtm3bGvfff7+Rl5dndWnV9sMPP5T73+j1119vGIY51NS//vUvIyIiwvD29jbOOecc47fffrO26Go40/nu3bv3tN9ZP/zwg9WlV9rZfrdl1edhpipyrq+99prRvn17w8fHx+jVq5fx2WefWVdwNZ3tfJOSkoxp06YZUVFRho+Pj9GpUyfjqaeeMlwul7WF1zGbYRhGrSZgEREREZFK0D2oIiIiIuJWFFBFRERExK0ooIqIiIiIW1FAFRERERG3ooAqIiIiIm5FAVVERERE3IoCqoiIiIi4FQVUEREREXErCqgiIiIi4lYUUEVERETErSigioiIiIhb+X8DCtJHpvmaWQAAAABJRU5ErkJggg=="},"metadata":{}}]}]}